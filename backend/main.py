from fastapi import FastAPI, UploadFile, File, Form
from loader import load_txt, load_pdf, clean_text, chunk_text
from embedder import Embedder
from weaviate_client import WeaviateVectorDB
import os
from llm_client import LLMClient
from rag_service import RAGService
from contextlib import asynccontextmanager
from fastapi.responses import StreamingResponse
# app = FastAPI(title="RAG PoC â€“ Retrieval Only")


# rag_service = RAGService(vector_db, llm_client)

# @app.on_event("startup")
# def startup():
#     global vector_db
#     vector_db = WeaviateVectorDB() 
#     vector_db.create_schema()   
#     print("Weaviate schema ready.")


embedder = Embedder()
vector_db = None  
llm_client = LLMClient()

@asynccontextmanager
async def lifespan(app: FastAPI):
    global vector_db
    vector_db = WeaviateVectorDB() 
    vector_db.create_schema()
    print("Weaviate schema ready.")
    
    global rag_service
    rag_service = RAGService(vector_db, llm_client)
    
    yield 

app = FastAPI(title="RAG PoC â€“ Retrieval Only", lifespan=lifespan)

@app.post("/upload")
async def upload_file(
    file: UploadFile = File(...),
    chunk_size: int = 600,
    overlap: int = 100
):
    # try:
    #     collection = vector_db.client.collections.get(vector_db.class_name)
    #     objects = collection.iterator()
    #     for obj in objects:
    #         collection.data.delete_by_id(obj.uuid)
    #     print("âœ… Ù‡Ù…Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø§Ú© Ø´Ø¯Ù†Ø¯.")
    # except Exception as e:
    #     print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ: {e}")

    tmp_path = f"/tmp/{file.filename}"
    os.makedirs("/tmp", exist_ok=True)

    with open(tmp_path, "wb") as f:
        f.write(await file.read())

    ext = file.filename.split(".")[-1].lower()
    text = load_pdf(tmp_path) if ext == "pdf" else load_txt(tmp_path)
    text = clean_text(text)

    chunks = chunk_text(text, chunk_size, overlap)
    vectors = embedder.encode(chunks)

    data = []
    for i, chunk in enumerate(chunks):
        data.append({
            "text": chunk,
            "vector": vectors[i],
            "source": file.filename
        })

    vector_db.add_chunks(data)

    # --- Ù„Ø§Ú¯ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯ ---
    print(f"ğŸ“Œ ØªØ¹Ø¯Ø§Ø¯ Ú†Ø§Ù†Ú©â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ {file.filename}: {len(data)}")
    for i, item in enumerate(data[:5]):  # ÙÙ‚Ø· Ûµ Ú†Ø§Ù†Ú© Ø§ÙˆÙ„ Ø±Ùˆ Ú†Ø§Ù¾ Ú©Ù† (Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù„Ø§Ú¯ Ø·ÙˆÙ„Ø§Ù†ÛŒ)
        print(f"Ú†Ø§Ù†Ú© {i+1}: source={item['source']} | Ù…ØªÙ† Ù†Ù…ÙˆÙ†Ù‡: {item['text'][:200]}... | vector Ø·ÙˆÙ„: {len(item['vector'])}")

    # ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ú†Ø§Ù†Ú©â€ŒÙ‡Ø§ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
    try:
        collection = vector_db.client.collections.get(vector_db.class_name)
        total = collection.aggregate.over_all(total_count=True).total_count
        print(f"ğŸ“Š Ù…Ø¬Ù…ÙˆØ¹ Ú†Ø§Ù†Ú©â€ŒÙ‡Ø§ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ø¹Ø¯ Ø§Ø² Ø¢Ù¾Ù„ÙˆØ¯: {total}")
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø´Ù…Ø§Ø±Ø´ Ú†Ø§Ù†Ú©â€ŒÙ‡Ø§: {e}")

    return {"status": "ok", "chunks_indexed": len(data)}



@app.post("/search")
async def search(q: str = Form(...), k: int = Form(5)):
    """
    Retrieval only â€“ no LLM, no query generation
    """
    query_vec = embedder.encode([q])[0]
    results = vector_db.search(query_vec, k)

    return {
        "query": q,
        "results": results
    }

@app.post("/query")
async def query_llm(q: str = Form(...), k: int = Form(5)):
    def event_stream():
        try:
            for token in rag_service.answer(q, k):
                yield token
        except Exception as e:
            yield f"\n\n Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®:{str(e)}"
    return StreamingResponse(event_stream(), media_type="text/plain; charset=utf-8")
 
برای پیاده‌سازی یک معماری RAG (Retrieval-Augmented Generation) ساده، بخش کلیدی‌اش embedding هست که متن‌ها (چانک‌های داکیومنت و کوئری کاربر) رو به بردارهای عددی تبدیل می‌کنه تا بتونیم شباهت معنایی رو محاسبه کنیم و اطلاعات مرتبط رو retrieve کنیم.
در ادامه، انواع اصلی embeddingها رو توضیح می‌دم و می‌گم هر کدوم کجا کاربرد دارن (بر اساس وضعیت فعلی در ۲۰۲۵):
۱. Dense Embeddings (بردارهای متراکم)
توضیح: بردارهایی با ابعاد ثابت (مثلاً ۷۶۸ یا ۱۰۲۴) که تقریباً همه مقادیرشون غیرصفره. معنای معنایی (semantic) متن رو به خوبی capture می‌کنن، حتی اگر کلمات دقیقاً مطابقت نداشته باشن (مثل synonymها یا paraphraseها).
کاربرد در RAG: استاندارد اصلی برای اکثر سیستم‌های RAG. عالی برای جستجوی معنایی وقتی کوئری و داکیومنت با کلمات متفاوت اما معنای مشابه نوشته شدن.
مدل‌های محبوب (۲۰۲۵):
OpenAI: text-embedding-3-large/small (عملکرد بالا، آسان از طریق API).
BGE (از BAAI، مثل bge-large-en-v1.5 یا BGE-M3): open-source، اغلب بهترین عملکرد در بنچمارک MTEB برای retrieval.
E5 (مثل intfloat/e5-large یا microsoft/e5): مخصوص retrieval، با prefixهای خاص عملکرد عالی داره.
gte-Qwen2 (از Alibaba، مثل gte-Qwen2-7B-instruct): جدید و قوی، مخصوصاً برای متن‌های پیچیده.
Snowflake Arctic Embed یا Mistral Embed: گزینه‌های خوب open-source با تعادل سرعت/دقت.
مزایا: دقت بالا در semantic search.
معایب: ممکنه در حوزه‌های تخصصی (مثل پزشکی یا حقوقی) با اصطلاحات نادر ضعیف عمل کنه.
۲. Sparse Embeddings (بردارهای پراکنده)
توضیح: بردارهایی با ابعاد خیلی بالا (مثل اندازه vocabulary) که بیشتر مقادیرشون صفره. شبیه BM25 یا TF-IDF، اما یادگرفته‌شده (learned) مثل مدل SPLADE یا BGE-M3 که sparse هم تولید می‌کنه.
کاربرد در RAG: عالی برای keyword matching دقیق و حوزه‌های تخصصی که اصطلاحات خاص مهمن. اغلب با dense ترکیب می‌شن (hybrid search) تا هم keyword دقیق داشته باشی هم semantic.
مزایا: interpretable (می‌تونی ببینی کدوم کلمات امتیاز دادن) و قوی در exact match.
معایب: کمتر semantic رو capture می‌کنه.
۳. Hybrid (Dense + Sparse)
توضیح: ترکیب دوتاشون (مثل BGE-M3 که همزمان dense و sparse تولید می‌کنه).
کاربرد: بهترین عملکرد کلی در RAGهای پیشرفته. برای داده‌های واقعی که هم نیاز به keyword دارن هم semantic، پیشنهاد می‌شه. بنچمارک‌ها نشون می‌دن hybrid اغلب از pure dense بهتره.
۴. Multimodal Embeddings
توضیح: embeddingهایی که متن + تصویر/ویدیو/صدا رو همزمان handle می‌کنن (مثل CLIP, SIGLIP یا مدل‌های جدید مثل Amazon Nova Multimodal).
کاربرد: وقتی داکیومنت‌هات شامل تصویر، چارت، جدول یا ویدیو باشه (مثل PDFهای فنی یا گزارش‌ها). برای RAG ساده متنی لازم نیست، اما اگر داده‌هات visual باشه، ضروری می‌شه.
پیشنهاد برای RAG ساده‌ات:
شروع ساده: از یک dense embedding خوب استفاده کن. اگر open-source می‌خوای: BGE-large یا e5-large (از Hugging Face). اگر API راحت می‌خوای: OpenAI text-embedding-3-large.
برای بهتر شدن: hybrid رو امتحان کن (مثل BGE-M3).
نکته مهم: همیشه روی داده‌های خودت evaluate کن (با metricهایی مثل recall@K یا nDCG). بنچمارک MTEB رو چک کن برای مقایسه مدل‌ها.


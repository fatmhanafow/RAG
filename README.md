<h1 align="center" style="color:#4B9CD3;">ğŸ¤– Local RAG System</h1>
<p align="center">
A <strong>production-ready local Retrieval-Augmented Generation (RAG) chatbot</strong> for TXT/PDF uploads, delivering precise, context-grounded answers. Persian OCR & multilingual support included.
</p>

---

## ğŸ”¹ Highlights

| Feature | Description |
|---------|-------------|
| ğŸ“ Persian OCR | Supports scanned PDFs (Tesseract `fas`) |
| ğŸŒ Multilingual | Persian â†” English queries |
| âš¡ Streaming | Token-by-token chat responses |
| ğŸ”„ Knowledge Reset | Automatic on each new upload |
| ğŸ–¥ï¸ RTL UI | Fully Streamlit-supported RTL rendering |
| ğŸ§© Modular | Separation of retrieval & generation pipelines |

---

## ğŸ—ï¸ Architecture

```text
User
â†“
Streamlit UI (RTL-safe)
â†“
FastAPI Backend
â”œâ”€â”€ Document Upload
â”œâ”€â”€ OCR (if scanned PDF)
â”œâ”€â”€ Chunking (overlap)
â”œâ”€â”€ Embedding Generation
â”œâ”€â”€ Weaviate Vector Storage
â”œâ”€â”€ Semantic Retrieval (top-k)
â””â”€â”€ LLM Query (Qwen3-32B API)
â†“
Streaming Token-by-Token Response
````

**Key Points:**

* ğŸ¯ Retrieval & generation separated
* ğŸ”— Modular pipeline
* ğŸ“ˆ Scalable (3000+ chunks)
* ğŸ› ï¸ Logging-ready

---

## âœ¨ Key Features

<div align="center">

| Icon | Feature         | Description                            |
| ---- | --------------- | -------------------------------------- |
| ğŸ“   | Persian OCR     | Tesseract `fas` for scanned/image PDFs |
| ğŸ“‚   | Multi-file      | Upload up to 20 files per batch        |
| ğŸ”—   | Chunking        | Overlapping semantic chunks            |
| ğŸ§    | Embeddings      | Lightweight 384-dim MiniLM             |
| ğŸ“š   | Vector Search   | Local top-k configurable               |
| âš¡    | Streaming       | Token-by-token chat like ChatGPT       |
| ğŸ”„   | Knowledge Reset | Clears context per upload              |
| ğŸŒ   | Multilingual    | Persian â†” English                      |
| ğŸ“Š   | Scalability     | Tested 3000+ chunks                    |
| ğŸ–¥ï¸  | RTL UI          | Full Persian support                   |

</div>

---

## ğŸ› ï¸ Tech Stack

| Layer           | Tools & Libraries                                                | Notes                              |
| --------------- | ---------------------------------------------------------------- | ---------------------------------- |
| **Backend**     | FastAPI, Weaviate v4, Sentence-Transformers (`all-MiniLM-L6-v2`) | API & embeddings                   |
| **Frontend**    | Streamlit                                                        | Interactive chat, streaming, RTL   |
| **OCR & Docs**  | Tesseract OCR (`fas`), PyMuPDF, Pillow                           | Text extraction & image conversion |
| **LLM**         | Qwen3-32B                                                        | Via internal edrac API             |
| **Other Tools** | Python 3.10+, Docker, docker-compose, requests                   | Local deployment & API calls       |

---

## ğŸš€ Installation & Local Setup

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue"/>
  <img src="https://img.shields.io/badge/Docker-ready-green"/>
</p>

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/fatmhanafow/RAG.git
cd RAG
```

### 2ï¸âƒ£ Create & Activate Virtual Environment

```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# Linux / macOS
source .venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Optional .env

```bash
# Add API keys/config if required
```

### 5ï¸âƒ£ Start Local Vector DB

```bash
docker-compose up -d
```

### 6ï¸âƒ£ Run Backend

```bash
uvicorn main:app --reload --port 8000
```

### 7ï¸âƒ£ Run Frontend

```bash
streamlit run app.py
```

ğŸŒ Open `http://localhost:8501`

---

## âš™ï¸ Example Workflow

<div align="left">
1ï¸âƒ£ Upload PDF/TXT files (scanned Persian supported)<br/>
2ï¸âƒ£ OCR & text extraction<br/>
3ï¸âƒ£ Chunking & embedding<br/>
4ï¸âƒ£ Store chunks in Weaviate<br/>
5ï¸âƒ£ Ask a question (Persian/English)<br/>
6ï¸âƒ£ Retrieve top-k relevant chunks<br/>
7ï¸âƒ£ LLM generates grounded answer<br/>
8ï¸âƒ£ Response streamed token-by-token
</div>

---

## ğŸ”® Future Improvements

* ğŸ”¹ Hybrid search (keyword + vector)
* ğŸ”¹ Reranking for better precision
* ğŸ”¹ Precision@k metrics
* ğŸ”¹ Query caching
* ğŸ”¹ Multimodal RAG (images)
* ğŸ”¹ Persistent multi-session memory
* ğŸ”¹ Full Docker deployment

---

## â¤ï¸ Why This Project Matters

* End-to-end **RAG system implementation**
* **Local vector DB integration**
* **Persian OCR handling**
* **Multilingual semantic retrieval**
* Streaming **LLM responses**
* RTL-safe **frontend engineering**
* Production-oriented **architecture design**

<p align="left">
  <img src="https://img.shields.io/badge/Powered_by-Python%203.10+-blue"/>
  <img src="https://img.shields.io/badge/Tech-FastAPI%2C_Streamlit-green"/>
</p>


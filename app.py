
# app.py
import streamlit as st
import requests

st.set_page_config(page_title="Ú†Øªâ€ŒØ¨Ø§Øª RAG Aptar", page_icon="ğŸ¤–", layout="wide")

st.markdown(
    """
    <style>
    /* ÙÙ‚Ø· Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú†Øª Ø±Ø§Ø³Øªâ€ŒØ¨Ù‡â€ŒÚ†Ù¾ Ø¨Ø´Ù† */
    .stChatMessage {
        direction: rtl !important;
        text-align: right !important;
    }

    /* ÙˆØ±ÙˆØ¯ÛŒ Ú†Øª Ù‡Ù… RTL Ø¨Ø§Ø´Ù‡ (Ú©Ø§Ø±Ø¨Ø± Ø±Ø§Ø­Øª ØªØ§ÛŒÙ¾ Ú©Ù†Ù‡) */
    .stChatInput > div > div > input,
    .stChatInput textarea {
        direction: rtl !important;
        text-align: right !important;
    }

    /* Ø¹Ù†ÙˆØ§Ù†â€ŒÙ‡Ø§ Ùˆ ØªÙˆØ¶ÛŒØ­Ø§Øª Ù‡Ù… RTL (Ø§Ø®ØªÛŒØ§Ø±ÛŒ Ø§Ù…Ø§ Ù‚Ø´Ù†Ú¯â€ŒØªØ±) */
    h1, h2, h3, .stMarkdown p {
        direction: rtl;
        text-align: right;
    }

    /* ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ */
    body, textarea, input {
        font-family: "Vazirmatn", "Tahoma", sans-serif;
    }

    /* Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ù‡â€ŒÙ‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ Ø§Ø¹Ø¯Ø§Ø¯ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¯Ø§Ø®Ù„ ÙØ§Ø±Ø³ÛŒ */
    .stMarkdown {
        unicode-bidi: plaintext;
    }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("ğŸ¤– RAG ChatBot")
st.markdown("Ø§Ø¨ØªØ¯Ø§ ÙØ§ÛŒÙ„ txt ÛŒØ§ pdf Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ØŒ Ø³Ù¾Ø³ Ø³ÙˆØ§Ù„ Ø¨Ù¾Ø±Ø³ÛŒØ¯. Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.")

BACKEND = "http://localhost:8000"

# --- Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± Ø¢Ù¾Ù„ÙˆØ¯ ---
with st.sidebar:
    st.header("Ø¢Ù¾Ù„ÙˆØ¯ Ø¯Ø§Ù†Ø´ Ù¾Ø§ÛŒÙ‡")
    uploaded_file = st.file_uploader(
            "ÙØ§ÛŒÙ„ txt ÛŒØ§ pdf Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯",
            type=["txt", "pdf"], 
            accept_multiple_files=True)
    
    if st.button("Ø¢Ù¾Ù„ÙˆØ¯ Ùˆ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§"):
        if uploaded_file:
            with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ Ùˆ Ø§ÛŒÙ†Ø¯Ú©Ø³ {len(uploaded_file)} ÙØ§ÛŒÙ„..."):
                all_chunks = 0
                for uploaded_file in uploaded_file:
                    files = {"file": (uploaded_file.name, uploaded_file.getvalue(), uploaded_file.type)}
                    try:
                        response = requests.post(f"{BACKEND}/upload", files=files, timeout=300)
                        response.raise_for_status()
                        result = response.json()
                        all_chunks += result.get('chunks_indexed', 0)
                        st.success(f"âœ… {uploaded_file.name}: {result.get('chunks_indexed', 0)} Ú†Ø§Ù†Ú© Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø´Ø¯.")
                    except Exception as e:
                        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± {uploaded_file.name}: {str(e)}")
                st.success(f"ğŸ‰ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯! Ù…Ø¬Ù…ÙˆØ¹ {all_chunks} Ú†Ø§Ù†Ú© Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø´Ø¯.")
        else:
            st.warning("âš ï¸ Ù„Ø·ÙØ§Ù‹ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© ÙØ§ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")

# --- Ú†Øª Ø§ØµÙ„ÛŒ ---
st.header("Ú†Øª Ø¨Ø§ Ø¨Ø§Øª")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Ù†Ù…Ø§ÛŒØ´ ØªØ§Ø±ÛŒØ®Ú†Ù‡ - ÙÙ‚Ø· Ø§ÛŒÙ†Ø¬Ø§ dir="rtl" Ù…ÛŒâ€ŒØ°Ø§Ø±ÛŒÙ…
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(f"<div style='direction: rtl; text-align: right;'>{message['content']}</div>", unsafe_allow_html=True)

# ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø±
if prompt := st.chat_input("Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯..."):
    # Ù…ØªÙ† Ø®Ø§Ù… Ùˆ ØªÙ…ÛŒØ² Ø±Ùˆ Ø¨Ù‡ Ø¨Ú©â€ŒØ§Ù†Ø¯ Ù…ÛŒâ€ŒÙØ±Ø³ØªÛŒÙ… (Ø¨Ø¯ÙˆÙ† Ù‡ÛŒÚ† dir ÛŒØ§ Ú©Ø§Ø±Ø§Ú©ØªØ± RTL Ù…Ø®ÙÛŒ)
    clean_prompt = prompt.strip()

    # Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ RTL
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(f"<div style='direction: rtl; text-align: right;'>{prompt}</div>", unsafe_allow_html=True)

    # Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù¾Ø§Ø³Ø® Ø¨Ø§Øª
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        try:
            response = requests.post(
                f"{BACKEND}/query",
                data={"q": clean_prompt, "k": 5},
                stream=True,
                timeout=120
            )
            response.raise_for_status()

            for chunk in response.iter_content(chunk_size=None, decode_unicode=True):
                if chunk:
                    full_response += chunk
                    message_placeholder.markdown(
                        f"<div style='direction: rtl; text-align: right;'>{full_response}â–Œ</div>",
                        unsafe_allow_html=True
                    )

            # Ù†Ù‡Ø§ÛŒÛŒ
            message_placeholder.markdown(
                f"<div style='direction: rtl; text-align: right;'>{full_response}</div>",
                unsafe_allow_html=True
            )

        except Exception as e:
            error_msg = "Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø® Ø±Ø® Ø¯Ø§Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒØ¯."
            message_placeholder.markdown(
                f"<div style='direction: rtl; text-align: right;'>{error_msg}</div>",
                unsafe_allow_html=True
            )
            full_response = error_msg

        st.session_state.messages.append({"role": "assistant", "content": full_response})

